{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain import PromptTemplate\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import Pinecone\n",
    "from langchain.document_loaders import PyMuPDFLoader, DirectoryLoader, PyPDFLoader\n",
    "from langchain.prompts import PromptTemplate   \n",
    "from langchain.llms import CTransformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (5.0.1)\n",
      "Requirement already satisfied: certifi>=2019.11.17 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (2024.8.30)\n",
      "Requirement already satisfied: pinecone-plugin-inference<2.0.0,>=1.0.3 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: pinecone-plugin-interface<0.0.8,>=0.0.7 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (0.0.7)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (4.12.2)\n",
      "Requirement already satisfied: urllib3>=1.26.5 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pinecone-client) (2.2.3)\n",
      "Requirement already satisfied: colorama in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from tqdm>=4.64.1->pinecone-client) (0.4.6)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade pinecone-client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jnaks\\anaconda3\\envs\\mchatbot\\Lib\\site-packages\\pinecone\\data\\index.py:1: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using index: medical-chatbot\n",
      "Index: medical-chatbot\n",
      "Environment: None\n"
     ]
    }
   ],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# Initialize Pinecone with your API key and environment\n",
    "pinecone = Pinecone(\n",
    "        api_key=\"pcsk_7dnp3_8P1Jf3H4k4CqfGugvz3NKQQH6p7nGMt76d4FTxzGCwWsCW5YzvGKaCUEuZLTKMA\",  # Replace with your actual API key\n",
    "        environment=\"us-east-1\"     # Replace with the correct region (e.g., \"us-west-2\")\n",
    ")\n",
    "  # Replace with your actual API key\n",
    "\n",
    "indexes = pinecone.list_indexes()\n",
    "\n",
    "if indexes :\n",
    "    index_name = indexes[0]['name']  # Use the actual index name here\n",
    "\n",
    "    index_name = str(index_name)\n",
    "    print(f\"Using index: {index_name}\")\n",
    "\n",
    "# Correctly interact with the index by passing the string name\n",
    "\n",
    "\n",
    "\n",
    "    # Describe the first index to get its details, including the environment\n",
    "    index_info = pinecone.describe_index(index_name)\n",
    "    print(f\"Index: {index_name}\")\n",
    "    print(f\"Environment: {index_info['environment']}\")\n",
    "else:\n",
    "    print('No indexes')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'deletion_protection': 'disabled',\n",
      " 'dimension': 384,\n",
      " 'host': 'medical-chatbot-zd36vrt.svc.aped-4627-b74a.pinecone.io',\n",
      " 'metric': 'cosine',\n",
      " 'name': 'medical-chatbot',\n",
      " 'spec': {'serverless': {'cloud': 'aws', 'region': 'us-east-1'}},\n",
      " 'status': {'ready': True, 'state': 'Ready'}}\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    index_info = pinecone.describe_index(\"medical-chatbot\")\n",
    "    print(index_info)\n",
    "except pinecone.exceptions.NotFoundError:\n",
    "    print(\"Index 'medical-chatbot' not found.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "PINECONE_API_KEY = \"pcsk_7dnp3_8P1Jf3H4k4CqfGugvz3NKQQH6p7nGMt76d4FTxzGCwWsCW5YzvGKaCUEuZLTKMA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pymupdf in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (1.24.14)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pymupdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pdfplumber in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (0.11.4)\n",
      "Requirement already satisfied: pdfminer.six==20231228 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pdfplumber) (20231228)\n",
      "Requirement already satisfied: Pillow>=9.1 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pdfplumber) (11.0.0)\n",
      "Requirement already satisfied: pypdfium2>=4.18.0 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pdfplumber) (4.30.0)\n",
      "Requirement already satisfied: charset-normalizer>=2.0.0 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (3.4.0)\n",
      "Requirement already satisfied: cryptography>=36.0.0 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pdfminer.six==20231228->pdfplumber) (44.0.0)\n",
      "Requirement already satisfied: cffi>=1.12 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (1.17.1)\n",
      "Requirement already satisfied: pycparser in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from cffi>=1.12->cryptography>=36.0.0->pdfminer.six==20231228->pdfplumber) (2.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pdfplumber\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pytesseract in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (0.3.13)Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Requirement already satisfied: pdf2image in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (1.17.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (11.0.0)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from pytesseract) (24.2)\n"
     ]
    }
   ],
   "source": [
    "pip install pytesseract pdf2image pillow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pypdf in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (5.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pypdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                             glob=\"*.pdf\",\n",
    "                             loader_cls = PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "    \n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_data = load_pdf(\"Data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size = 500, chunk_overlap = 20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "\n",
    "    return text_chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length:  5860\n"
     ]
    }
   ],
   "source": [
    "text_chunks = text_split(extracted_data)\n",
    "print(\"length: \", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting sentence-transformersNote: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Cannot install sentence-transformers==0.1.0, sentence-transformers==0.2.0, sentence-transformers==0.2.1, sentence-transformers==0.2.2, sentence-transformers==0.2.3, sentence-transformers==0.2.4, sentence-transformers==0.2.4.1, sentence-transformers==0.2.5, sentence-transformers==0.2.5.1, sentence-transformers==0.2.6.1, sentence-transformers==0.2.6.2, sentence-transformers==0.3.0, sentence-transformers==0.3.1, sentence-transformers==0.3.2, sentence-transformers==0.3.3, sentence-transformers==0.3.4, sentence-transformers==0.3.5, sentence-transformers==0.3.5.1, sentence-transformers==0.3.6, sentence-transformers==0.3.7, sentence-transformers==0.3.7.1, sentence-transformers==0.3.7.2, sentence-transformers==0.3.8, sentence-transformers==0.3.9, sentence-transformers==0.4.0, sentence-transformers==0.4.1, sentence-transformers==0.4.1.1, sentence-transformers==0.4.1.2, sentence-transformers==1.0.0, sentence-transformers==1.0.1, sentence-transformers==1.0.2, sentence-transformers==1.0.3, sentence-transformers==1.0.4, sentence-transformers==1.1.0, sentence-transformers==1.1.1, sentence-transformers==1.2.0, sentence-transformers==1.2.1, sentence-transformers==2.0.0, sentence-transformers==2.1.0, sentence-transformers==2.2.0, sentence-transformers==2.2.1, sentence-transformers==2.2.2, sentence-transformers==2.3.0, sentence-transformers==2.3.1, sentence-transformers==2.4.0, sentence-transformers==2.5.0, sentence-transformers==2.5.1, sentence-transformers==2.6.0, sentence-transformers==2.6.1, sentence-transformers==2.7.0, sentence-transformers==3.0.0, sentence-transformers==3.0.1, sentence-transformers==3.1.0, sentence-transformers==3.1.1, sentence-transformers==3.2.0, sentence-transformers==3.2.1, sentence-transformers==3.3.0 and sentence-transformers==3.3.1 because these package versions have conflicting dependencies.\n",
      "ERROR: ResolutionImpossible: for help visit https://pip.pypa.io/en/latest/topics/dependency-resolution/#dealing-with-dependency-conflicts\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Using cached sentence_transformers-3.3.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting transformers<5.0.0,>=4.41.0 (from sentence-transformers)\n",
      "  Using cached transformers-4.47.0-py3-none-any.whl.metadata (43 kB)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jnaks\\anaconda3\\envs\\mchatbot\\lib\\site-packages (from sentence-transformers) (4.67.1)\n",
      "INFO: pip is looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence_transformers-3.3.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.2.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.2.0-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.1.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.1.0-py3-none-any.whl.metadata (23 kB)\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "  Using cached sentence_transformers-3.0.0-py3-none-any.whl.metadata (10 kB)\n",
      "INFO: pip is still looking at multiple versions of sentence-transformers to determine which version is compatible with other requirements. This could take a while.\n",
      "  Using cached sentence_transformers-2.7.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.6.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.5.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.5.0-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Using cached sentence_transformers-2.4.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.3.1-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence_transformers-2.3.0-py3-none-any.whl.metadata (11 kB)\n",
      "  Using cached sentence-transformers-2.2.2.tar.gz (85 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-2.2.1.tar.gz (84 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-2.2.0.tar.gz (79 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-2.1.0.tar.gz (78 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting tokenizers>=0.10.3 (from sentence-transformers)\n",
      "  Using cached tokenizers-0.21.0-cp39-abi3-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-2.0.0.tar.gz (85 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.2.1.tar.gz (80 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.2.0.tar.gz (81 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.1.1.tar.gz (81 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.1.0.tar.gz (78 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.4.tar.gz (74 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.3.tar.gz (74 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.2.tar.gz (74 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.1.tar.gz (74 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-1.0.0.tar.gz (74 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.1.2.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.1.1.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.1.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.4.0.tar.gz (65 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.9.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers<3.6.0,>=3.1.0 (from sentence-transformers)\n",
      "  Using cached transformers-3.5.1-py3-none-any.whl.metadata (32 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.8.tar.gz (66 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers<3.4.0,>=3.1.0 (from sentence-transformers)\n",
      "  Using cached transformers-3.3.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.7.2.tar.gz (59 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.7.1.tar.gz (59 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.7.tar.gz (59 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.6.tar.gz (62 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers<3.2.0,>=3.1.0 (from sentence-transformers)\n",
      "  Using cached transformers-3.1.0-py3-none-any.whl.metadata (49 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.5.1.tar.gz (61 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers==3.0.2 (from sentence-transformers)\n",
      "  Using cached transformers-3.0.2-py3-none-any.whl.metadata (44 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.3.5.tar.gz (61 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.4.tar.gz (61 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.3.tar.gz (65 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.2.tar.gz (65 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.1.tar.gz (64 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.3.0.tar.gz (61 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.6.2.tar.gz (60 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers==2.11.0 (from sentence-transformers)\n",
      "  Using cached transformers-2.11.0-py3-none-any.whl.metadata (45 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.6.1.tar.gz (55 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.5.1.tar.gz (52 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers==2.3.0 (from sentence-transformers)\n",
      "  Using cached transformers-2.3.0-py3-none-any.whl.metadata (38 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.5.tar.gz (49 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.4.1.tar.gz (49 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting transformers==2.2.1 (from sentence-transformers)\n",
      "  Using cached transformers-2.2.1-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.4.tar.gz (49 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.3.tar.gz (45 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytorch-transformers==1.1.0 (from sentence-transformers)\n",
      "  Using cached pytorch_transformers-1.1.0-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.2.tar.gz (44 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.2.1.tar.gz (42 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Collecting pytorch-transformers==1.0.0 (from sentence-transformers)\n",
      "  Using cached pytorch_transformers-1.0.0-py3-none-any.whl.metadata (19 kB)\n",
      "Collecting sentence-transformers\n",
      "  Using cached sentence-transformers-0.2.0.tar.gz (28 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "  Using cached sentence-transformers-0.1.0.tar.gz (35 kB)\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "\n",
      "The conflict is caused by:\n",
      "    sentence-transformers 3.3.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.3.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.2.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.2.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.1.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.1.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.0.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 3.0.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.7.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.6.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.6.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.5.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.5.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.4.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.3.1 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.3.0 depends on torch>=1.11.0\n",
      "    sentence-transformers 2.2.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.2.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.2.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.1.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 2.0.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.2.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.2.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.1.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.1.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.4 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.3 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 1.0.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1.2 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.1 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.4.0 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.3.9 depends on torch>=1.6.0\n",
      "    sentence-transformers 0.3.8 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7.2 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.7 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.6 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.5.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.5 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.4 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.3 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.2 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.1 depends on torch>=1.2.0\n",
      "    sentence-transformers 0.3.0 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.6.2 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.6.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.5.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.5 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.4.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.4 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.3 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.2 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.1 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.2.0 depends on torch>=1.0.1\n",
      "    sentence-transformers 0.1.0 depends on torch>=1.0.1\n",
      "\n",
      "To fix this you could try to:\n",
      "1. loosen the range of package versions you've specified\n",
      "2. remove package versions to allow pip to attempt to solve the dependency conflict\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pip install -U sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download The embedding model\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\jnaks\\anaconda3\\envs\\mchatbot\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:84\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mdownload_hugging_face_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[13], line 3\u001b[0m, in \u001b[0;36mdownload_hugging_face_embeddings\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdownload_hugging_face_embeddings\u001b[39m():\n\u001b[1;32m----> 3\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43mHuggingFaceEmbeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msentence-transformers/all-MiniLM-L6-v2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "File \u001b[1;32mc:\\Users\\jnaks\\anaconda3\\envs\\mchatbot\\Lib\\site-packages\\langchain_core\\_api\\deprecation.py:216\u001b[0m, in \u001b[0;36mdeprecated.<locals>.deprecate.<locals>.finalize.<locals>.warn_if_direct_instance\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     warned \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m    215\u001b[0m     emit_warning()\n\u001b[1;32m--> 216\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\jnaks\\anaconda3\\envs\\mchatbot\\Lib\\site-packages\\langchain_community\\embeddings\\huggingface.py:87\u001b[0m, in \u001b[0;36mHuggingFaceEmbeddings.__init__\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msentence_transformers\u001b[39;00m\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m---> 87\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\n\u001b[0;32m     88\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not import sentence_transformers python package. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     89\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease install it with `pip install sentence-transformers`.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     90\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient \u001b[38;5;241m=\u001b[39m sentence_transformers\u001b[38;5;241m.\u001b[39mSentenceTransformer(\n\u001b[0;32m     93\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_name, cache_folder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_folder, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs\n\u001b[0;32m     94\u001b[0m )\n",
      "\u001b[1;31mImportError\u001b[0m: Could not import sentence_transformers python package. Please install it with `pip install sentence-transformers`."
     ]
    }
   ],
   "source": [
    "embeddings = download_hugging_face_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
